<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>VR Training - Holographic Box</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<style>
  body { margin: 0; overflow: hidden; background: #000; font-family: 'Courier New', monospace; }
  canvas { display: block; }

  /* UI Overlays */
  #ui-layer {
    position: fixed;
    inset: 0;
    pointer-events: none;
    border: 20px solid rgba(0, 255, 204, 0.1);
    box-sizing: border-box;
    z-index: 5;
  }

  #status {
    position: fixed;
    top: 30px;
    left: 30px;
    color: #00ffcc;
    text-shadow: 0 0 8px #00ffcc;
    font-size: 14px;
    letter-spacing: 2px;
  }

  /* Video Preview */
  #v-prev {
    position: fixed;
    bottom: 20px;
    right: 20px;
    width: 150px;
    border: 1px solid #00ffcc;
    border-radius: 4px;
    transform: scaleX(-1);
    opacity: 0.4;
    filter: grayscale(100%) brightness(1.5);
  }

  /* Scanline Effect */
  #ui-layer::after {
    content: " ";
    position: absolute;
    inset: 0;
    background: linear-gradient(rgba(18, 16, 16, 0) 50%, rgba(0, 0, 0, 0.25) 50%), 
                linear-gradient(90deg, rgba(255, 0, 0, 0.06), rgba(0, 255, 0, 0.02), rgba(0, 0, 255, 0.06));
    background-size: 100% 4px, 3px 100%;
    pointer-events: none;
  }

  #loading {
    position: fixed;
    inset: 0;
    background: black;
    display: flex;
    justify-content: center;
    align-items: center;
    color: #00ffcc;
    z-index: 100;
  }
</style>
</head>
<body>

<div id="loading">INITIALIZING NEURAL LINK...</div>

<div id="ui-layer">
  <div id="status">
    <b>SIMULATOR PHASE: 01</b><br>
    HEAD TRACKING: <span id="track-stat">CONNECTING...</span><br>
    DEPTH: 800mm
  </div>
</div>

<video id="v-prev" autoplay playsinline></video>

<script type="importmap">
{
  "imports": {
    "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
    "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/"
  }
}
</script>

<script type="module">
import * as THREE from "three";
import { FaceLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.7";

/* ───────── CONFIG ───────── */
const BOX_DEPTH = 120;
const TEXT_MESSAGES = ["ANALYZING BIOMETRICS", "UPLOADING CORE", "STABILIZING SYNC", "DECRYPTING...", "SYSTEM READY"];

/* ───────── THREE.JS SCENE ───────── */
const scene = new THREE.Scene();
scene.fog = new THREE.Fog(0x000000, 10, 150);

const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
// Default position
camera.position.z = 10;

const renderer = new THREE.WebGLRenderer({ antialias: true });
renderer.setSize(window.innerWidth, window.innerHeight);
renderer.setPixelRatio(window.devicePixelRatio);
document.body.appendChild(renderer.domElement);

/* ───────── THE "WINDOW" BOX ───────── */
// Create the interior of the box using wireframe walls
const boxGroup = new THREE.Group();
const wallMat = new THREE.MeshBasicMaterial({ 
    color: 0x00ffcc, 
    wireframe: true, 
    transparent: true, 
    opacity: 0.15 
});

const wallGeom = new THREE.PlaneGeometry(60, BOX_DEPTH);

// Floor
const floor = new THREE.Mesh(wallGeom, wallMat);
floor.rotation.x = -Math.PI / 2;
floor.position.y = -20;
floor.position.z = -BOX_DEPTH / 2;
boxGroup.add(floor);

// Ceiling
const ceiling = new THREE.Mesh(wallGeom, wallMat);
ceiling.rotation.x = Math.PI / 2;
ceiling.position.y = 20;
ceiling.position.z = -BOX_DEPTH / 2;
boxGroup.add(ceiling);

// Left Wall
const leftWall = new THREE.Mesh(wallGeom, wallMat);
leftWall.rotation.y = Math.PI / 2;
leftWall.position.x = -30;
leftWall.position.z = -BOX_DEPTH / 2;
boxGroup.add(leftWall);

// Right Wall
const rightWall = new THREE.Mesh(wallGeom, wallMat);
rightWall.rotation.y = -Math.PI / 2;
rightWall.position.x = 30;
rightWall.position.z = -BOX_DEPTH / 2;
boxGroup.add(rightWall);

scene.add(boxGroup);

/* ───────── FLYING TEXT SYSTEM ───────── */
const textElements = [];

function createTextSprite(text) {
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');
    canvas.width = 512; canvas.height = 128;
    ctx.fillStyle = '#00ffcc';
    ctx.font = 'bold 32px Courier New';
    ctx.textAlign = 'center';
    ctx.shadowBlur = 10;
    ctx.shadowColor = "#00ffcc";
    ctx.fillText(text, 256, 64);
    
    const texture = new THREE.CanvasTexture(canvas);
    const sprite = new THREE.Sprite(new THREE.SpriteMaterial({ map: texture, transparent: true }));
    sprite.scale.set(12, 3, 1);
    
    // Random position at the back of the box
    sprite.position.set(
        (Math.random() - 0.5) * 40,
        (Math.random() - 0.5) * 25,
        -BOX_DEPTH
    );
    return sprite;
}

// Spawn new text every 1.5 seconds
setInterval(() => {
    const msg = TEXT_MESSAGES[Math.floor(Math.random() * TEXT_MESSAGES.length)];
    const sprite = createTextSprite(msg);
    scene.add(sprite);
    textElements.push(sprite);
}, 1500);

/* ───────── HEAD TRACKING (MEDIAPIPE) ───────── */
let landmarker;
let video = document.createElement("video");
const videoPrev = document.getElementById("v-prev");
let headPos = { x: 0, y: 0 };

async function initTracking() {
    const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.7/wasm");
    landmarker = await FaceLandmarker.createFromOptions(vision, {
        baseOptions: { modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task" },
        runningMode: "VIDEO"
    });

    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
    video.srcObject = videoPrev.srcObject = stream;
    video.play();
    
    document.getElementById("loading").style.display = "none";
    document.getElementById("track-stat").innerText = "SYNCED";
    animate();
}

/* ───────── ANIMATION LOOP ───────── */
function animate() {
    requestAnimationFrame(animate);

    // 1. Process Head Tracking
    if (landmarker && video.readyState >= 2) {
        const results = landmarker.detectForVideo(video, performance.now());
        if (results.faceLandmarks?.[0]) {
            const nose = results.faceLandmarks[0][1]; // Tip of nose
            // Smoothly lerp towards target head position
            headPos.x += ((nose.x - 0.5) * -45 - headPos.x) * 0.1;
            headPos.y += ((nose.y - 0.5) * -30 - headPos.y) * 0.1;
        }
    }

    // 2. Update Camera (The "Holographic" Perspective)
    camera.position.x = headPos.x;
    camera.position.y = headPos.y;
    camera.lookAt(0, 0, -BOX_DEPTH / 2); // Look into the center of the box

    // 3. Animate Text toward camera
    for (let i = textElements.length - 1; i >= 0; i--) {
        const t = textElements[i];
        t.position.z += 0.5; // Speed of text moving forward
        
        // Fade in/out
        const dist = Math.abs(t.position.z);
        t.material.opacity = THREE.MathUtils.smoothstep(dist, 0, 100);

        // Remove if passed camera
        if (t.position.z > 15) {
            scene.remove(t);
            textElements.splice(i, 1);
        }
    }

    renderer.render(scene, camera);
}

// Handle Window Resize
window.addEventListener("resize", () => {
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
    renderer.setSize(window.innerWidth, window.innerHeight);
});

initTracking();
</script>
</body>
</html>
